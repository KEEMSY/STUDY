# **Performance In Multithreaded Applications**

성능에 대한 이야기는 **두가지**를 이야기할 수 있다.

 ***성능은 시나리오와 용례에 따라 완전히 다르게 측정될 수 있음을 명심하자.***

- `지연시간(Latency)`: **시간단위로 측정되는 작업 하나의 완료시간** 을 의미한다.
- `처리량(Throughput)`: **일정시간동안 완료한 작업의 양** 으로, 시간 단위 당 작업으로 측정된다.

<br><hr><hr>

## **지연시간, Latency**

멀테스레딩 프로그래밍에서 이론적으로 지연시간(latency)을 다음과 같은 방법으로 줄일 수 있다.

- 싱글스레드에서 순차적으로 완료할 수 있는 하나의 작업에서의 지연시간을 T 라고한다. 그리고 하위 작업을 병렬로 실행되도록 각자 다른 스레드에 스케줄링하여 지연시간(T) 를 하위 작업의 갯수(N) 로 나눈다.

<br>

이론적인 목표를 달성하기 위해서는 다음 질문에 답이 필요하다.

- ### **하위작업의 갯수(N)은 무엇이며, 몇개로 나누워야 하는가?**

    > **일반적인 컴퓨터의 코어의 갯수와 최대한 비슷해야한다.**

    하위 작업들을 모두 병렬로 실행하면 지연시간이 줄어들기 때문이다. 하위 작업은 다른 코어에서 실행하는 경우에만 완전히 병렬로 실행할 수 있다. 이론적으로, **중요한 것이 같은 컴퓨터에서 실행되고 있지 않다면 운영체제는 다른 코어로 다른 작업을 스케줄링하고 최대한 하드웨어를 활용하여 최적의 성능을 제공한다.** 하나의 스레드만 추가해도 생산성이 떨어져 성능이 저하되고 지연시간은 늘어난다. 추가된 스레드는 다른 스레드를 코어에서 앞뒤로 밀어내어 컨텍스트 스위치, 캐시 성능 저하 추가 메모리 소비가 증가한다.

    `스레드 개수 == 코어갯수` 는 모든 스레드가 인터럽트 없이 하위 작업을 실행해야 최적이다. 즉 모든 스레드가 항상 `runaable` 상태여야함을 의미한다. `IO`나 `블로킹 호출`도 없어야 한다.(***현실에서는 매우 힘들다.***)

    시스템에서 CPU를 많이 소모 하는 것은 실행되고 있지 않아야 한다.

    <br>

- ### **원래작업을 분할하고 하위 작업을 스케줄링하여 나중에 합치는 것에는 어떤 트레이드오프가 존재하는가?**

    > **작업을 여러개로 쉽게 나눴다면 그 절차가 수반하는 비용은 감수해야 한다.**

    이 비용에는 작업을 **작은 세그먼트로 나누나 실행했던 몇몇 계산과 스레드 생성비용, 스레드에 작업을 전달하고 시작하는 비용, 운영체제가 스레드를 실제로 스케줄링해 스레드가 실행되기 까지의 시간**이 포함된다. 또한 마지막 스레드가 완료되고 집계가 완료되었다는 신호또한 기다려야한다.(결과를 얻는 과정)

    **멀티 스레드 솔루션에서도 지연시간은 꾸준히 증가한다.** 하지만 **기존 작업이 길고 무거울수록 작업을 분할해 병렬로 실행할 가치가 있다.** 그리고 가치판단의 기준점은 **멀티 스레드 솔루션과 싱글 스레드의 교차점**이다.

    **작고 세세한 작업**은 굳이 분할하고 병행으로 실행할 가치가 없다.

    <br>

- ### **어떤 작업이든 원하는 만큼 하위 작업으로 나눌 수 있는가?**

    > **모든 작업을 여러 개별 작업으로 나누고 병행으로 실행할 수 없다.**

    작업은 **3가지** 유형으로 분류 할 수 있다.

  - 본질적으로 병행 가능하며 하위 작업으로 쉽게 분할 되는 작업
  - 분할이 불가능해 처음부터 끝까지 싱글 스레드를 쓸 수 밖에 없는 작업
  - 부분적으로 하위 작업으로 나눌 수 있고 순차적으로 실행해야 하는 작업

<br><hr><hr>

## **처리량, Throughput**

처리량은 **주어진 기간에 완성되는 작업의 수**를 말한다.

- **시간단위**, 특히 **초** 단위로 작업을 나눠 처리량을 측정한다.

<br>

> ### **애플리케이션 처리량 개선 방법의 접근 법**

**1. taks를 subtasks로 나눈다.**

- 작업을 완료하는데 `T 시간`(latency) 이 걸린다면 이룰 수 있는 최소 처리량은 `1`이거나 `1/T` 이다.

- Sub-task 를 나란히 실행하면 `N/T` 의 최대 처리량을 얻게된다.(`latency = T/N`)

    *`T` - Time to execute origin task || `N` - sub task / threads*

    - 하지만 `N/T` 보다 **낮은 처리량** 을 얻을 확률이 높다.
    - 여러 작업으로 나누고 스케줄링 한 후 하나로 결합하는데에는 **비용** 이 들기 때문이다.
    - 이는 처리량에 있어 **완전히 불필요한 작업** 이라고 말한 수 있다.

**2. 각 작업을 별개 스레드에 스케줄링 한다.** 

- 이론적으로 처리량(throughput)은 `N/T`가 된다.(`latency = T`)
- 작업이 내부적으로 연관되지 않고 **별개** 이기 때문에 **이론적인 처리량을 얻을 확률이 매우 높다.**
- 따라서 각 작업들을 작은 작업으로 나눠야 하는 **전처리 필요성을 없앨 수 있다.**
- 작업은 각각의 하나의 결과만 갖기 때문에 작업을 **포스트 프로세스할 필요가 없다.**
- 완전히 별개의 작업이기 때문에 다른 작업의 완료를 위해 **기다리지 않아도 된다.**
- `스레드 풀링`, `논블로킹 큐` 와같은 고급기술을 사용할 **필요가 없이 최적의 처리량**을 얻을 수 있다.

<br><hr><hr>

## **Thread Pooing**

**스레드를 생성하고 미래 작업을 위해 다시 스레드를 사용하는 것** 을 말한다. 스레드는 계속 이용하여 **최대 처리량** 과 **리소스의 최대 사용률** 을 얻을 수 있다.

- 스레드가 생성되면 풀에 쌓이고 작업이 대기열을 통해 스레드별로 분배된다.
- 스레드는 이용 가능할 때마다 대기열을 통해 작업을 받는다.
- 모든 스레드가 바쁘면 대기열에 머무르며 스레드가 이용 가능해질 때까지 기다린다.
- 스레드 풀을 이용하여 일정한 수의 스레드를 유지할 수 있고 작업을 할 때마다 스레드를 재 생성할 필요를 제거할 수 있다.